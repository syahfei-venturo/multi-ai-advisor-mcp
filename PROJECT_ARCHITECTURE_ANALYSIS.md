# Multi-Model Advisor MCP Server - Architecture Analysis

**Document Version:** 1.0  
**Generated:** November 13, 2025  
**Project:** Multi-Model Advisor MCP Server  
**Analyzed Files:** 7 core files (config, database, jobqueue, retry, index)

---

## ğŸ“‹ Executive Summary

Multi-Model Advisor adalah MCP (Model Context Protocol) server yang menghubungkan Claude Desktop dengan multiple Ollama models secara parallel, menciptakan "council of advisors". Project ini menggunakan **async job-based architecture** dengan persistent database untuk conversation history dan job tracking.

**Key Characteristics:**
- ğŸ”„ Non-blocking async job submission
- ğŸ—„ï¸ SQLite database dengan WAL mode untuk concurrency
- ğŸ”Œ Circuit breaker + exponential backoff retry mechanism
- âš™ï¸ Flexible configuration (CLI args, env vars, defaults)
- ğŸ’­ Support untuk sequential thinking analysis
- ğŸ” Real-time progress tracking dengan time estimation

---

## 1. Arsitektur Keseluruhan

### 1.1 Component Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Claude for Desktop (Client)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         MCP Protocol
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Model Advisor MCP                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Tools Layer    â”‚  â”‚  Job Queue Mgmt  â”‚  â”‚  Lifecycle  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ query-models     â”‚  â”‚ get-job-progress â”‚  â”‚ onStart     â”‚  â”‚
â”‚  â”‚ analyze-thinking â”‚  â”‚ get-job-result   â”‚  â”‚ onComplete  â”‚  â”‚
â”‚  â”‚ health-check     â”‚  â”‚ list-jobs        â”‚  â”‚ onFailure   â”‚  â”‚
â”‚  â”‚ list-jobs        â”‚  â”‚ cancel-job       â”‚  â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              JobQueue (Async Execution)                  â”‚  â”‚
â”‚  â”‚  â€¢ Pending Queue (FIFO)                                  â”‚  â”‚
â”‚  â”‚  â€¢ Running Map (maxConcurrent: 2-100)                    â”‚  â”‚
â”‚  â”‚  â€¢ Completed Map (with cleanup)                          â”‚  â”‚
â”‚  â”‚  â€¢ Progress tracking with time estimation                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Execution Layer (Query Models)                  â”‚  â”‚
â”‚  â”‚  â€¢ Ollama Circuit Breaker (5 failures, 60s reset)        â”‚  â”‚
â”‚  â”‚  â€¢ Parallel model queries (Promise.all)                  â”‚  â”‚
â”‚  â”‚  â€¢ Retry with exponential backoff (4 attempts)           â”‚  â”‚
â”‚  â”‚  â€¢ Conversation context inclusion                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Storage & Persistence                            â”‚  â”‚
â”‚  â”‚  â€¢ Database (SQLite WAL mode)                            â”‚  â”‚
â”‚  â”‚    â”œâ”€ conversations table (+ indexes)                    â”‚  â”‚
â”‚  â”‚    â”œâ”€ session_metadata table                             â”‚  â”‚
â”‚  â”‚    â”œâ”€ jobs table                                         â”‚  â”‚
â”‚  â”‚    â””â”€ job_progress table                                 â”‚  â”‚
â”‚  â”‚  â€¢ In-memory conversation history (40 msg max/session)   â”‚  â”‚
â”‚  â”‚  â€¢ Job cache (all jobs until cleanup)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Configuration & Setup                            â”‚  â”‚
â”‚  â”‚  â€¢ Config (CLI args, env vars, defaults)                 â”‚  â”‚
â”‚  â”‚  â€¢ Zod validation with detailed error messages           â”‚  â”‚
â”‚  â”‚  â€¢ Dynamic system prompts per model                      â”‚  â”‚
â”‚  â”‚  â€¢ Thinking steps configuration                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ollama API (http://localhost:11434)                            â”‚
â”‚    â”œâ”€ /api/generate (query with system prompt)                  â”‚
â”‚    â””â”€ /api/tags (model availability check)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Design Patterns

| Pattern | Usage | Location |
|---------|-------|----------|
| **Async Job Queue** | Non-blocking task execution dengan status tracking | `jobqueue.ts` |
| **Circuit Breaker** | Fault tolerance untuk Ollama API calls | `retry.ts` + `index.ts` |
| **Exponential Backoff** | Retry strategy dengan jitter untuk resilience | `retry.ts` |
| **Repository Pattern** | Database abstraction untuk persistence | `database.ts` |
| **Singleton** | Global database instance dan job queue | `database.ts`, `jobqueue.ts` |
| **Observer Pattern** | Job lifecycle callbacks (onJobStarted) | `jobqueue.ts` + `index.ts` |
| **Strategy Pattern** | Different system prompts per model | `config.ts` + `index.ts` |
| **Factory Pattern** | Dynamic tool registration pada MCP server | `index.ts` |

### 1.3 Data Flow

**Query Models Flow:**
```
User Request
    â†“
query-models Tool (index.ts)
    â†“
Validate input + estimate time
    â†“
Submit Job to Queue â†’ Return Job ID immediately (non-blocking)
    â†“
JobQueue.processQueue() â†’ Move from pending to running
    â†“
onJobStarted callback triggered
    â†“
executeQueryModelJob() parallel execution:
    â”œâ”€ Load conversation history
    â”œâ”€ Build prompt with context
    â”œâ”€ Query model 1 (with retry + circuit breaker)
    â”œâ”€ Query model 2 (with retry + circuit breaker)
    â””â”€ Query model 3 (with retry + circuit breaker)
    â†“
Save responses to database
    â†“
Format result + completeJob()
    â†“
User retrieves via get-job-result (polling)
```

**Conversation History Flow:**
```
executeQueryModelJob() saves each response
    â†“
Persist to database via db.saveMessage()
    â†“
Also store in-memory conversationHistory[sessionId]
    â†“
User loads via manage-conversation tool
    â†“
On server restart:
    â”œâ”€ Database restored to memory
    â””â”€ Incomplete jobs resubmitted
```

---

## 2. Job Queue System

### 2.1 Architecture

```typescript
// Job Lifecycle
Pending â†’ Running â†’ Completed
           â†“         â”œâ”€ Success
           â”‚         â”œâ”€ Failed
           â”‚         â””â”€ Cancelled
           â””â”€ (Cancelled before start)
```

### 2.2 Implementation Details

**Job Structure:**
```typescript
interface Job {
  id: string;                      // UUID v4
  type: 'query-models' | 'analyze-thinking';
  status: 'pending' | 'running' | 'completed' | 'failed' | 'cancelled';
  progress: number;                // 0-100%
  createdAt: Date;
  startedAt?: Date;
  completedAt?: Date;
  input: Record<string, unknown>;
  result?: unknown;
  error?: string;
  progressUpdates: ProgressUpdate[];
  estimatedCompletionMs?: number;  // Adaptive estimation
  estimatedTotalMs?: number;
  modelCount?: number;
}
```

**Concurrency Management:**
```typescript
class JobQueue {
  private pending: Job[] = [];              // FIFO queue
  private running: Map<string, Job>;        // Active jobs
  private completed: Map<string, Job>;      // History
  maxConcurrent: number = 3;                // Default, configurable
}
```

**Submission & Execution:**
```typescript
submitJob(type, input, estimatedMs?, modelCount?)
  â†’ Create job with initial estimation
  â†’ Push to pending queue
  â†’ processQueue()
    â†’ Move from pending to running (up to maxConcurrent)
    â†’ Set job.startedAt
    â†’ Trigger onJobStarted callback
      â†’ Server's executeQueryModelJob(job)
        â†’ Update progress asynchronously
        â†’ Call completeJob() or failJob()
```

### 2.3 Progress Tracking & Time Estimation

**Initial Estimation (at submission):**
```typescript
// Regular query
estimatedMs = modelsCount * 10000;  // ~10s per model

// With thinking
estimatedMs = modelsCount * (3000 + thinkingSteps * 1000);
// Min 3s + 1s per step, so 5-13s per model
```

**Adaptive Estimation (during execution):**
```typescript
if (elapsedMs > 0 && progress > 1%) {
  // Recalculate based on actual progress
  estimatedTotal = elapsedMs / (progress / 100);
  estimatedRemaining = estimatedTotal - elapsedMs;
}
```

**Progress Updates Format:**
```
[timestamp, message, percentage]
- [5%] 2025-11-13T12:23:37Z: Preparing query execution
- [10%] 2025-11-13T12:23:37Z: Querying gemma3:1b...
- [45%] 2025-11-13T12:23:50Z: Querying deepseek-r1...
- [100%] 2025-11-13T12:24:08Z: Completed
```

### 2.4 Queue Management

**Processing Strategy:**
- FIFO (First-In-First-Out) for fairness
- Process queue triggers on every completion
- Each pending job moves to running when slot available

**Cleanup Strategy:**
```typescript
clearOldJobs(hoursOld = 24)
  â†’ Delete completed jobs older than 24 hours
  â†’ Keeps recent jobs for debugging/reference
```

**Current Limitations:**
- âŒ Max 2-100 concurrent jobs (very conservative default: 2)
- âŒ All completed jobs kept in memory indefinitely
- âŒ No prioritization or scheduling
- âŒ No job dependencies or grouping

---

## 3. Database Architecture

### 3.1 Schema Design

**Tables:**

1. **conversations** (Main persistence)
   ```sql
   CREATE TABLE conversations (
     id INTEGER PRIMARY KEY AUTOINCREMENT,
     session_id TEXT NOT NULL,
     message_index INTEGER NOT NULL,
     role TEXT NOT NULL,                 -- 'user' or 'assistant'
     content TEXT NOT NULL,              -- Full message
     model_name TEXT,                    -- Model that generated response
     thinking_text TEXT,                 -- Internal thinking (optional)
     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
     UNIQUE(session_id, message_index)
   );
   ```

2. **session_metadata** (Session info)
   ```sql
   CREATE TABLE session_metadata (
     session_id TEXT PRIMARY KEY,
     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
     last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
     message_count INTEGER DEFAULT 0,
     user_metadata TEXT
   );
   ```

3. **jobs** (Job tracking)
   ```sql
   CREATE TABLE jobs (
     id TEXT PRIMARY KEY,
     type TEXT NOT NULL,
     status TEXT NOT NULL,
     progress INTEGER DEFAULT 0,
     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
     started_at TIMESTAMP,
     completed_at TIMESTAMP,
     input TEXT NOT NULL,                -- JSON serialized
     result TEXT,                        -- JSON serialized
     error TEXT
   );
   ```

4. **job_progress** (Detailed progress)
   ```sql
   CREATE TABLE job_progress (
     id INTEGER PRIMARY KEY AUTOINCREMENT,
     job_id TEXT NOT NULL,
     timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
     message TEXT NOT NULL,
     percentage INTEGER,
     FOREIGN KEY (job_id) REFERENCES jobs(id) ON DELETE CASCADE
   );
   ```

**Indexes:**
- `idx_session_id` on conversations(session_id)
- `idx_created_at` on conversations(created_at)
- `idx_session_created` on conversations(session_id, created_at)
- `idx_last_accessed` on session_metadata(last_accessed)
- `idx_job_status` on jobs(status)
- `idx_job_created` on jobs(created_at)
- `idx_job_progress_id` on job_progress(job_id)

### 3.2 Data Persistence Strategy

**SQLite Configuration:**
```typescript
db.pragma('journal_mode = WAL');       // Write-Ahead Logging
db.pragma('synchronous = NORMAL');     // Balanced performance/safety
db.pragma('foreign_keys = ON');        // Referential integrity
```

**Benefits:**
- âœ… WAL mode: Better concurrency, allows readers + writer simultaneously
- âœ… NORMAL sync: Good balance between durability and speed
- âœ… Foreign keys: Automatic cascade delete for job_progress

**Limitations:**
- âŒ No sharding or replication
- âŒ SQLite max ~100 concurrent connections (overkill for this use case)
- âŒ File-based: not suitable for distributed systems

### 3.3 Data Loading on Startup

```typescript
// 1. Load existing sessions from database
loadExistingSessions()
  â†’ getAllSessions()
  â†’ For each session:
    â””â”€ loadSessionHistory(sessionId)
       â†’ Populate conversationHistory[sessionId]

// 2. Restore incomplete jobs
restoreIncompleteJobs()
  â†’ getAllJobs()
  â†’ Filter: status == 'pending' or status == 'running'
  â†’ Resubmit to jobQueue (fresh job ID)
  â†’ This prevents job loss on restart
```

### 3.4 Cleanup & Maintenance

**Automatic Cleanup:**
- `deleteJobsByAge(hoursOld = 24)` - Manual call needed
- `deleteSessionsByAge(days = 30)` - Manual call needed

**Current Issues:**
- âŒ No automatic cleanup scheduled
- âŒ Must be called manually or via external cron
- âŒ Database can grow indefinitely

### 3.5 Performance Characteristics

**Read Performance:**
- Session history load: O(n) where n = messages in session
- Job status lookup: O(1) via primary key
- All jobs query: O(m) where m = total jobs

**Write Performance:**
- Message save: O(1) with WAL mode
- Job progress update: O(1) insert
- Batch inserts: Possible with transactions (not currently used)

**Storage Efficiency:**
- ~5KB per 100-message session
- ~1KB per completed job
- Database file size reported in health check

---

## 4. Error Handling & Resilience

### 4.1 Circuit Breaker Pattern

**Implementation:**
```typescript
class CircuitBreaker {
  private failureCount = 0;
  private failureThreshold = 5;
  private resetTimeout = 60000;  // 1 minute
  
  states: 'CLOSED' | 'OPEN' | 'HALF_OPEN'
}
```

**Flow:**
```
CLOSED (normal)
  â†’ 5 consecutive failures
  â†’ OPEN (reject requests)
    â†’ 60s passes
    â†’ HALF_OPEN (test recovery)
      â†’ If succeeds: CLOSED
      â†’ If fails: OPEN
```

**Usage:**
```typescript
ollamaCircuitBreaker.execute(async () => {
  return withRetry(
    async () => fetch(`${OLLAMA_API_URL}/api/generate`, ...),
    RETRY_CONFIG,
    undefined
  );
});
```

**Benefits:**
- âœ… Fast-fail when Ollama is down
- âœ… Prevents cascading failures
- âœ… Auto-recovery after timeout

### 4.2 Retry Mechanism

**Configuration:**
```typescript
RETRY_CONFIG = {
  maxAttempts: 4,              // env: RETRY_MAX_ATTEMPTS
  initialDelayMs: 3000,        // env: RETRY_INITIAL_DELAY_MS
  maxDelayMs: 10000,           // env: RETRY_MAX_DELAY_MS
  multiplier: 2,               // exponential backoff
  timeoutMs: 500000,           // 500s = 8.3 minutes (hardcoded!)
}
```

**Retry Algorithm:**
```typescript
async function withRetry(
  fn: AsyncFunction,
  config: RetryConfig,
  errorLog?: ErrorLog
) {
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await executeWithTimeout(fn, config.timeoutMs);
    } catch (error) {
      if (attempt < maxAttempts && isRetryableError(error)) {
        const delay = Math.min(
          initialDelayMs * (multiplier ^ (attempt - 1)),
          maxDelayMs
        );
        await sleep(delay);
      } else {
        throw;
      }
    }
  }
}
```

**Retryable Errors:**
```typescript
const RETRYABLE_ERRORS = [
  'ECONNREFUSED',
  'ECONNRESET',
  'ETIMEDOUT',
  'EHOSTUNREACH',
  'HTTP 502',
  'HTTP 503',
  'HTTP 504'
];
```

**Exponential Backoff with Jitter:**
```
Attempt 1 fails â†’ wait 3000ms
Attempt 2 fails â†’ wait 6000ms
Attempt 3 fails â†’ wait 10000ms (capped at maxDelayMs)
Attempt 4 fails â†’ throw error
```

### 4.3 Error Response Handling

**Model-Level Errors:**
```typescript
responses.forEach((resp) => {
  if (resp.error) {
    // Circuit breaker open?
    if (errorMessage.includes("Circuit breaker is OPEN")) {
      return `âš ï¸ Service temporarily unavailable (circuit breaker active)`;
    }
    // Generic error
    return `Error: Could not get response from ${modelName}`;
  }
});
```

**Job-Level Errors:**
```typescript
try {
  // Execute job
  completeJob(jobId, result);
} catch (error) {
  failJob(jobId, error.message);
}
```

**Database Errors:**
```typescript
try {
  db.saveMessage(...);
} catch (dbError) {
  // Log warning but don't fail job
  console.error("Error saving to database:", dbError);
  // Continue with in-memory history
}
```

### 4.4 Graceful Degradation

**Scenario 1: All Models Fail**
- Job completes with error responses
- User sees "Error: Could not get response" for each model
- Job status = 'completed' (not 'failed')

**Scenario 2: Database Unavailable**
- Messages still saved in-memory
- Job completes successfully
- Database warnings logged

**Scenario 3: Ollama Down**
- Circuit breaker opens after 5 failures
- Subsequent requests fail fast
- Users get informative error messages

**Scenario 4: Timeout**
- Current timeout: 30s (for retries)
- Each retry has separate timeout
- Max total time: ~30s + (retries Ã— backoff)

---

## 5. Configuration Management

### 5.1 Configuration Hierarchy

**Precedence (highest to lowest):**
1. **CLI Arguments** - `node build/index.js --ollama-url http://...`
2. **Environment Variables** - `.env` file or shell env
3. **Defaults** - Hardcoded in config.ts

**Implementation:**
```typescript
const getString = (cliKey: string, envKey: string, defaultValue: string) => {
  if (cliArgs[cliKey]) return String(cliArgs[cliKey]);           // #1 CLI
  return process.env[envKey] || defaultValue;                   // #2 Env, #3 Default
};
```

### 5.2 Configuration Parameters

**Server Configuration:**
```
SERVER_NAME              (CLI: --server-name)              [default: multi-model-advisor]
SERVER_VERSION           (CLI: --server-version)           [default: 1.0.0]
DEBUG                    (CLI: --debug)                    [default: false]
```

**Ollama Configuration:**
```
OLLAMA_API_URL           (CLI: --ollama-url)               [default: http://localhost:11434]
DEFAULT_MODELS           (CLI: --models)                   [default: gemma3:1b,llama3.2:1b,deepseek-r1:1.5b]
```

**Job Queue Configuration:**
```
MAX_CONCURRENT_JOBS      (CLI: --max-concurrent-jobs)      [default: 2] (range: 1-100)
RETRY_MAX_ATTEMPTS       (CLI: --retry-attempts)           [default: 4] (range: 1-10)
RETRY_INITIAL_DELAY_MS   (CLI: --retry-initial-delay)      [default: 3000] (range: 100-10000)
RETRY_MAX_DELAY_MS       (CLI: --retry-max-delay)          [default: 10000] (range: 1000-60000)
```

**Thinking Configuration:**
```
DEFAULT_THINKING_STEPS   (CLI: --default-thinking-steps)   [default: 3] (range: 1-5)
MAX_THINKING_STEPS       (CLI: --max-thinking-steps)       [default: 4] (range: 1-5)
```

**Dynamic System Prompts:**
```
MODEL_1_PROMPT (or MODEL_{N}_PROMPT)                       [pattern-based lookup]
${MODEL_NAME}_SYSTEM_PROMPT                                [model name mapping]
--model1-prompt "..." (or --model{N}-prompt)               [CLI override]
```

### 5.3 Configuration Validation with Zod

**Schema Definition:**
```typescript
const ConfigSchema = z.object({
  server: z.object({
    name: z.string().min(1),
    version: z.string().min(1),
    debug: z.boolean(),
  }),
  ollama: z.object({
    apiUrl: z.string().url(),              // Must be valid URL
    models: z.array(z.string()).min(1),    // At least 1 model
  }),
  prompts: z.record(z.string()),
  thinking: z.object(...).optional(),
  jobQueue: z.object(...).optional(),
});
```

**Error Handling:**
```
If validation fails:
  âŒ Print friendly error messages
  âœ… Show which config items are invalid
  âœ… Print helpful tips for fixing
  âœ… Exit with code 1
```

### 5.4 Dynamic System Prompts

**Prompt Resolution Logic:**
```typescript
For each model:
  1. Check CLI: --model{N}-prompt
  2. Check CLI: --{modelPrefix}-prompt
  3. Check ENV: MODEL_{N}_PROMPT
  4. Check ENV: {MODEL_NAME}_SYSTEM_PROMPT
  5. Default: "You are a helpful AI assistant (${model})"
```

**Example:**
```bash
# .env
GEMMA_SYSTEM_PROMPT="You are creative"
MODEL_2_PROMPT="You are helpful"

# CLI override
node build/index.js --model1-prompt "You are analytical"

# Result for [gemma3:1b, gemma3:1b, gemma3:1b]:
# Model 1: "You are analytical"              (CLI wins)
# Model 2: "You are helpful"                (ENV MODEL_2_PROMPT)
# Model 3: "You are a helpful AI assistant" (default)
```

### 5.5 Issues & Limitations

**Potential Problems:**
- âš ï¸ URL validation only checks format, not reachability
- âš ï¸ Model list not validated against Ollama availability
- âš ï¸ Timeout (500s) is hardcoded in RETRY_CONFIG
- âš ï¸ Job queue maxConcurrent default (2) is very conservative
- âš ï¸ No warning if configuration contradicts Ollama models available

---

## 6. Strengths & Weaknesses

### 6.1 Strengths âœ…

1. **Non-Blocking Async Architecture**
   - âœ… Job submission returns immediately
   - âœ… Clients can poll progress independently
   - âœ… Server can handle multiple concurrent queries
   - âœ… Better user experience (no hanging)

2. **Robust Error Handling**
   - âœ… Circuit breaker prevents cascading failures
   - âœ… Exponential backoff for intelligent retries
   - âœ… Graceful degradation when partial models fail
   - âœ… Comprehensive error logging with context

3. **Persistent Conversation History**
   - âœ… SQLite with WAL for efficient concurrency
   - âœ… Both in-memory and database persistence
   - âœ… Session restoration on server restart
   - âœ… Job state recovery for incomplete jobs

4. **Flexible Configuration System**
   - âœ… CLI args + env vars + defaults
   - âœ… Zod validation with detailed error messages
   - âœ… Dynamic system prompts per model
   - âœ… Bounds checking and constraints

5. **Parallel Model Querying**
   - âœ… All models queried simultaneously (3Ã— speedup)
   - âœ… Faster response times
   - âœ… Better resource utilization
   - âœ… Independent retry per model

6. **Real-Time Progress Tracking**
   - âœ… Accurate progress updates
   - âœ… Estimated time remaining
   - âœ… Visual feedback for long-running operations
   - âœ… Timestamp-based debugging

7. **Think Tool for Deep Analysis**
   - âœ… Sequential thinking support
   - âœ… Configurable thinking steps
   - âœ… Multiple models compare reasoning
   - âœ… Educational value for understanding AI decisions

8. **Health Check & Monitoring**
   - âœ… System status visibility
   - âœ… Component health reporting
   - âœ… Database statistics
   - âœ… Ollama connectivity checks

9. **Structured Data Management**
   - âœ… Well-designed database schema
   - âœ… Proper indexing for queries
   - âœ… Foreign key constraints
   - âœ… Pagination support for large histories

### 6.2 Weaknesses & Limitations âŒ

1. **Very Conservative Concurrency**
   - âŒ Max concurrent jobs default: 2 (hardcoded)
   - âŒ Single job blocks up to 10+ seconds
   - âŒ Potential bottleneck for multiple users
   - âš ï¸ Can cause queue buildup
   - ğŸ”§ **Fix:** Increase maxConcurrentJobs to 5-10, make configurable

2. **Incomplete Job Persistence**
   - âŒ Job progress updates not persisted to database
   - âŒ Progress only stored in-memory
   - âŒ Job loss on server crash mid-execution
   - âŒ Adaptive time estimates not recovered
   - ğŸ”§ **Fix:** Save progress updates to database in real-time

3. **Unbounded In-Memory History**
   - âŒ Conversation history kept in-memory per session
   - âŒ No hard limit until 40 messages (client-side)
   - âŒ Large sessions could consume significant memory
   - âš ï¸ No automatic cleanup in background
   - ğŸ”§ **Fix:** Implement memory limits with LRU eviction

4. **Hardcoded Timeout Values**
   - âŒ Retry timeout: 500s (hardcoded in RETRY_CONFIG)
   - âŒ Not configurable via CLI/env
   - âŒ Cannot adapt to slow networks or large models
   - ğŸ”§ **Fix:** Make timeout configurable

5. **No Result Streaming**
   - âŒ Full results buffered in memory
   - âŒ Long responses could use significant memory
   - âŒ No way to get partial results
   - ğŸ”§ **Fix:** Implement streaming results to client

6. **Manual Database Cleanup Required**
   - âŒ No automatic deletion of old jobs/sessions
   - âŒ Database grows indefinitely
   - âŒ Must call cleanup manually
   - âš ï¸ No scheduled cleanup task
   - ğŸ”§ **Fix:** Implement background cleanup timer

7. **Limited Job Cancellation**
   - âŒ Can only cancel pending jobs
   - âŒ Running jobs cannot be truly cancelled
   - âŒ No graceful shutdown of ongoing queries
   - ğŸ”§ **Fix:** Add job cancellation signal handling

8. **No Test Coverage Visible**
   - âŒ Test files exist but appear to be basic stubs
   - âŒ No integration tests for job queue
   - âŒ No error scenario testing
   - âŒ Database persistence not tested
   - ğŸ”§ **Fix:** Comprehensive test suite (unit + integration + e2e)

9. **No Rate Limiting**
   - âŒ No per-client rate limits
   - âŒ No per-session throttling
   - âŒ Potential for abuse with many rapid requests
   - ğŸ”§ **Fix:** Implement token bucket or sliding window rate limiting

10. **Limited Logging & Observability**
    - âŒ Only basic console.error logging
    - âŒ No structured logging (JSON)
    - âŒ No metrics export (Prometheus)
    - âŒ No distributed tracing support
    - ğŸ”§ **Fix:** Winston/Pino logging + OpenTelemetry metrics

---

## 7. Recommendations untuk Improvement

### 7.1 High Priority (Implement First)

#### 1. Increase Default Concurrency
**Current:** maxConcurrentJobs = 2  
**Recommended:** 5-10 (based on testing)
```typescript
// config.ts
jobQueueConfig = {
  maxConcurrentJobs: getNumber('max-concurrent-jobs', 'MAX_CONCURRENT_JOBS', 5), // Was: 2
  // ...
};
```
**Impact:** Reduce job queue wait time, better resource utilization

#### 2. Persist Job Progress to Database
**Benefit:** Job state recovery on crash
```typescript
// jobqueue.ts
updateProgress(jobId: string, progress: number, message: string) {
  // Existing in-memory update...
  
  // NEW: Persist to database
  try {
    const db = getDatabase();
    db.saveJobProgress(jobId, new Date(), message, progress);
  } catch (error) {
    console.error("Error saving job progress:", error);
  }
}
```

#### 3. Make Timeout Configurable
**Current:** Hardcoded 500s  
**Fix:**
```typescript
// config.ts
RETRY_CONFIG = {
  timeoutMs: getNumber('retry-timeout', 'RETRY_TIMEOUT_MS', 500000),
};
```

#### 4. Automatic Database Cleanup
**Implementation:**
```typescript
// index.ts - in main()
setInterval(() => {
  const clearedJobs = jobQueue.clearOldJobs(24);      // 24 hours
  const clearedSessions = db.deleteSessionsByAge(30); // 30 days
  debugLog(`Cleanup: ${clearedJobs} jobs, ${clearedSessions} sessions`);
}, 6 * 60 * 60 * 1000); // Every 6 hours
```

#### 5. Comprehensive Test Coverage
**Add tests for:**
```typescript
// tests/
â”œâ”€â”€ jobqueue.test.ts (DONE - basic)
â”œâ”€â”€ database.test.ts (DONE - basic)
â”œâ”€â”€ config.test.ts (validation edge cases)
â”œâ”€â”€ integration.test.ts (NEW - full flow)
â”œâ”€â”€ error-handling.test.ts (NEW - circuit breaker, retry)
â”œâ”€â”€ model-failures.test.ts (NEW - partial failures)
â””â”€â”€ performance.test.ts (NEW - concurrent jobs)
```

### 7.2 Medium Priority

#### 6. Implement Memory Limits
```typescript
// jobqueue.ts
const MAX_IN_MEMORY_HISTORY_PER_SESSION = 1000; // Was: unlimited

if (conversationHistory[sessionId].length > MAX_IN_MEMORY_HISTORY_PER_SESSION) {
  // Load older messages only on demand from database
  conversationHistory[sessionId] = 
    conversationHistory[sessionId].slice(-500);
}
```

#### 7. Implement Proper Job Cancellation
```typescript
// jobqueue.ts
async function cancelJob(jobId: string): Promise<void> {
  const job = this.running.get(jobId);
  if (job) {
    job.abortController?.abort();  // Signal to stop execution
    job.status = 'cancelled';
    // Wait for cleanup...
  }
}
```

#### 8. Add Rate Limiting
```typescript
// NEW: ratelimit.ts
class TokenBucket {
  async acquire(tokens: number = 1): Promise<void> {
    // Token bucket algorithm
  }
}

// Usage in index.ts
const rateLimiter = new TokenBucket({
  capacity: 100,      // Max 100 jobs queued
  refillRate: 10,     // 10 jobs per second
});

// In tool handlers
await rateLimiter.acquire(1);
```

#### 9. Structured Logging
```typescript
// NEW: logger.ts
const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  transport: {
    target: 'pino-pretty'
  }
});

// Usage throughout
logger.info({ jobId, progress }, 'Job progress updated');
logger.error({ error: e.message, jobId }, 'Job failed');
```

#### 10. Metrics & Observability
```typescript
// NEW: metrics.ts
import { metrics } from '@opentelemetry/sdk-node';

const jobCounter = new Counter('jobs_total', 'Total jobs');
const jobDuration = new Histogram('job_duration_ms', 'Job duration');
const queueSize = new Gauge('queue_size', 'Pending jobs');
```

### 7.3 Low Priority (Nice to Have)

#### 11. Result Streaming
```typescript
server.tool('query-models-streaming', ..., async (input) => {
  // Return stream of results as models complete
  // Implementation depends on MCP protocol support
});
```

#### 12. Job Dependencies & Grouping
```typescript
// Allow: job_b depends_on job_a
// Batch multiple jobs: group_submit([job1, job2, job3])
```

#### 13. Model Fallback Chain
```typescript
// If primary model fails, try secondary model
// Configuration: fallback_models = ["llama3:latest", "neural-chat"]
```

#### 14. Distributed Tracing
```typescript
// OpenTelemetry tracing for request flow
// Jaeger or Zipkin export
```

#### 15. WebSocket Support
```typescript
// Real-time progress updates instead of polling
// Reduced latency and network overhead
```

### 7.4 Implementation Priority Matrix

| Feature | Priority | Effort | Impact | Timeline |
|---------|----------|--------|--------|----------|
| Increase concurrency | ğŸ”´ HIGH | ğŸŸ¢ Low | ğŸ”´ HIGH | Week 1 |
| Persist job progress | ğŸ”´ HIGH | ğŸŸ¡ Medium | ğŸ”´ HIGH | Week 1 |
| Make timeout configurable | ğŸ”´ HIGH | ğŸŸ¢ Low | ğŸŸ¡ Medium | Week 1 |
| Auto database cleanup | ğŸ”´ HIGH | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Week 1 |
| Comprehensive tests | ğŸ”´ HIGH | ğŸ”´ High | ğŸ”´ HIGH | Week 2-3 |
| Memory limits | ğŸŸ¡ MEDIUM | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Week 2 |
| Job cancellation | ğŸŸ¡ MEDIUM | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Week 2 |
| Rate limiting | ğŸŸ¡ MEDIUM | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Week 2 |
| Structured logging | ğŸŸ¡ MEDIUM | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Week 3 |
| Metrics/observability | ğŸŸ¢ LOW | ğŸ”´ High | ğŸŸ¡ Medium | Week 4 |
| Result streaming | ğŸŸ¢ LOW | ğŸ”´ High | ğŸŸ¡ Medium | Future |
| Job dependencies | ğŸŸ¢ LOW | ğŸ”´ High | ğŸŸ¢ Low | Future |
| Model fallback | ğŸŸ¢ LOW | ğŸŸ¡ Medium | ğŸŸ¡ Medium | Future |
| Distributed tracing | ğŸŸ¢ LOW | ğŸ”´ High | ğŸŸ¡ Medium | Future |
| WebSocket support | ğŸŸ¢ LOW | ğŸ”´ High | ğŸŸ¡ Medium | Future |

---

## 8. Conclusion & Summary

### 8.1 Project Maturity Assessment

| Aspect | Maturity | Notes |
|--------|----------|-------|
| **Architecture** | â­â­â­â­ (4/5) | Well-designed async patterns, minor scaling issues |
| **Error Handling** | â­â­â­â­ (4/5) | Circuit breaker + retry excellent, but limited visibility |
| **Persistence** | â­â­â­ (3/5) | Good design, but incomplete job state persistence |
| **Testing** | â­â­ (2/5) | Basic test files, needs comprehensive coverage |
| **Documentation** | â­â­â­ (3/5) | Good README and ASYNC_JOB_SYSTEM.md, lacks code comments |
| **Observability** | â­â­ (2/5) | Basic logging, no metrics or structured logs |
| **Configuration** | â­â­â­â­ (4/5) | Flexible and validated, very user-friendly |
| **Performance** | â­â­â­ (3/5) | Good parallelization, conservative concurrency |

### 8.2 Use Cases

**âœ… Best Suited For:**
- Single-user or small team environments
- Development and experimentation
- Quick prototyping with multiple AI perspectives
- Educational purposes (learning AI concepts)
- Local Ollama instances

**âš ï¸ Needs Improvements Before:**
- Multi-user production environments
- High-throughput scenarios (100+ jobs/hour)
- Long-lived conversations (1000+ messages)
- Large distributed deployments

### 8.3 Key Takeaways

1. **Excellent Foundation** - Well-structured async architecture with good error handling
2. **Scaling Ready** - Can be made production-ready with specific improvements
3. **User Focused** - Configuration flexibility and real-time feedback demonstrate good UX thinking
4. **Persistence-aware** - Database integration shows maturity in state management
5. **Needs Polish** - Testing, logging, and some scaling issues prevent production deployment

### 8.4 Recommended Next Steps

**Immediate (This Week):**
1. Review and implement all 5 high-priority recommendations
2. Set up CI/CD pipeline for automated testing
3. Add Zod validation for Ollama connectivity

**Short-term (This Month):**
1. Complete test coverage (unit + integration)
2. Add structured logging
3. Implement rate limiting

**Medium-term (Next 2 Months):**
1. Add observability (metrics + tracing)
2. Implement streaming results
3. Performance testing & optimization

**Long-term (Roadmap):**
1. Distributed deployment support
2. Advanced scheduling and job dependencies
3. WebSocket/real-time updates
4. Model auto-discovery and fallback chains

---

## Appendix: File Structure Reference

```
multi-ai-advisor-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # Main MCP server, tool handlers, execution logic
â”‚   â”œâ”€â”€ config.ts                   # Configuration management, validation
â”‚   â”œâ”€â”€ jobqueue.ts                 # Job queue implementation, lifecycle
â”‚   â”œâ”€â”€ database.ts                 # SQLite persistence layer
â”‚   â”œâ”€â”€ retry.ts                    # Circuit breaker, retry mechanism
â”‚
â”œâ”€â”€ build/                          # Compiled JavaScript (auto-generated)
â”‚   â”œâ”€â”€ index.js
â”‚   â”œâ”€â”€ config.js
â”‚   â”œâ”€â”€ jobqueue.js
â”‚   â”œâ”€â”€ database.js
â”‚   â”œâ”€â”€ retry.js
â”‚
â”œâ”€â”€ data/                           # Runtime data
â”‚   â””â”€â”€ conversations.db            # SQLite database
â”‚
â”œâ”€â”€ tests/                          # Test files
â”‚   â”œâ”€â”€ database.test.ts
â”‚   â”œâ”€â”€ jobqueue.test.ts
â”‚   â””â”€â”€ retry.test.ts
â”‚
â”œâ”€â”€ package.json                    # Dependencies and scripts
â”œâ”€â”€ tsconfig.json                   # TypeScript configuration
â”œâ”€â”€ jest.config.cjs                 # Jest testing framework
â”œâ”€â”€ README.md                        # User documentation
â”œâ”€â”€ ASYNC_JOB_SYSTEM.md            # Technical documentation
â””â”€â”€ PROJECT_ARCHITECTURE_ANALYSIS.md # This file
```

---

## Document Metadata

- **Version:** 1.0
- **Last Updated:** November 13, 2025
- **Author:** Architecture Analysis
- **Status:** Final
- **Audience:** Developers, Architects, DevOps Engineers

**How to Use This Document:**
1. **Architecture Overview** - Read Section 1 for system understanding
2. **Implementation Details** - Sections 2-5 for deep dives
3. **Quality Assessment** - Section 6 for strengths/weaknesses
4. **Action Items** - Section 7 for improvements roadmap

---
