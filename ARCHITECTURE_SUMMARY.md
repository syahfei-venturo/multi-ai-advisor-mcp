# Multi-Model Advisor - Architecture Summary (Quick Reference)

## ğŸ¯ Project Overview

**Multi-Model Advisor** adalah MCP (Model Context Protocol) server yang mengintegrasikan Claude Desktop dengan multiple Ollama models, memberikan "council of advisors" approach.

```
User (Claude Desktop)
         â†“
    MCP Server (this project)
         â†“
    [Job Queue] â†’ Async execution
         â†“
    Parallel Model Queries â†’ [gemma3, llama3, deepseek]
         â†“
    Results + Conversation History
         â†“
    Claude synthesizes & responds
```

---

## ğŸ—ï¸ Architecture at a Glance

### Components

| Component | File | Responsibility |
|-----------|------|-----------------|
| **MCP Server** | `index.ts` | Tool definitions, request handling, execution orchestration |
| **Job Queue** | `jobqueue.ts` | Async job submission, lifecycle management, concurrency control |
| **Database** | `database.ts` | SQLite persistence for conversations & jobs |
| **Configuration** | `config.ts` | CLI/env/defaults parsing, validation with Zod |
| **Retry Logic** | `retry.ts` | Circuit breaker, exponential backoff, error handling |

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SUBMISSION (Non-blocking)                                â”‚
â”‚                                                              â”‚
â”‚   query-models(question) â†’ Create Job â†’ Submit to Queue    â”‚
â”‚   Return Job ID immediately âœ“                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. EXECUTION (Background)                                   â”‚
â”‚                                                              â”‚
â”‚   Job starts â†’ Query models in parallel:                   â”‚
â”‚   â€¢ Model 1 with retry + circuit breaker                   â”‚
â”‚   â€¢ Model 2 with retry + circuit breaker                   â”‚
â”‚   â€¢ Model 3 with retry + circuit breaker                   â”‚
â”‚   Update progress continuously                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PERSISTENCE (Real-time)                                  â”‚
â”‚                                                              â”‚
â”‚   Save to database: messages, job progress, results         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RETRIEVAL (Poll-based)                                   â”‚
â”‚                                                              â”‚
â”‚   get-job-progress(job_id) â†’ Current status & time estimate â”‚
â”‚   get-job-result(job_id) â†’ Full results when ready âœ“       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Job Queue System

### Lifecycle States

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   PENDING   â”‚ (waiting in queue)
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚ slot available
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚   RUNNING   â”‚ (executing)
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
        â”‚DONE â”‚ â”‚ FAILED â”‚ â”‚CANCELLED
        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

```typescript
maxConcurrentJobs: 2         // Very conservative!
                             // Recommended: 5-10
```

### Progress Tracking

```
Start: [5%] Starting query...
       [15%] Querying model 1...
       [35%] Querying model 2...
       [65%] Querying model 3...
       [85%] Processing responses...
Done:  [100%] Completed!

Time Estimate:
- Initial: Based on model count (10s Ã— 3 = 30s)
- Adaptive: Recalculates based on actual progress
```

---

## ğŸ’¾ Database Schema

### Tables

```sql
conversations
â”œâ”€ session_id (foreign key to sessions)
â”œâ”€ message_index (order in conversation)
â”œâ”€ role (user/assistant)
â”œâ”€ content (message text)
â”œâ”€ model_name (which model generated it)
â””â”€ thinking_text (internal reasoning)

session_metadata
â”œâ”€ session_id (primary key)
â”œâ”€ created_at
â”œâ”€ last_accessed (for cleanup)
â””â”€ message_count

jobs
â”œâ”€ id (primary key)
â”œâ”€ type (query-models/analyze-thinking)
â”œâ”€ status (pending/running/completed/failed)
â”œâ”€ progress (0-100)
â”œâ”€ input (serialized JSON)
â””â”€ result (serialized JSON)

job_progress
â”œâ”€ job_id (foreign key)
â”œâ”€ timestamp
â”œâ”€ message
â””â”€ percentage
```

### Indexing Strategy

```
conversations:
  âœ“ idx_session_id           (most queries)
  âœ“ idx_session_created      (range queries)

session_metadata:
  âœ“ idx_last_accessed        (cleanup queries)

jobs:
  âœ“ idx_job_status           (status filtering)
  âœ“ idx_job_created          (time-based queries)
```

**SQLite Mode:** WAL (Write-Ahead Logging) for better concurrency

---

## ğŸ›¡ï¸ Error Handling

### Circuit Breaker

```
CLOSED (normal operation)
  â”‚
  â”œâ”€ 5 failures occur
  â”‚
  â””â”€â†’ OPEN (reject requests)
       â”‚
       â””â”€ 60 seconds pass
          â”‚
          â””â”€â†’ HALF_OPEN (test recovery)
              â”‚
              â”œâ”€ Request succeeds
              â”‚  â””â”€â†’ CLOSED âœ“
              â”‚
              â””â”€ Request fails
                 â””â”€â†’ OPEN
```

### Retry Mechanism

```
Attempt 1: âŒ wait 3000ms
Attempt 2: âŒ wait 6000ms
Attempt 3: âŒ wait 10000ms (capped)
Attempt 4: âŒ throw error

Total time: up to 19s for retries
```

### Supported Retry Conditions

```
âœ“ ECONNREFUSED (connection refused)
âœ“ ECONNRESET (connection reset)
âœ“ ETIMEDOUT (timeout)
âœ“ HTTP 502 (bad gateway)
âœ“ HTTP 503 (service unavailable)
âœ“ HTTP 504 (gateway timeout)
```

---

## âš™ï¸ Configuration System

### Precedence

```
CLI Arguments (highest)
    â†“
Environment Variables
    â†“
Default Values (lowest)
```

### Example Configurations

**Basic Start:**
```bash
npm start
# Uses .env or defaults
```

**Custom Models:**
```bash
node build/index.js \
  --models llama3:latest,neural-chat,mistral \
  --model1-prompt "You are funny" \
  --model2-prompt "You are helpful"
```

**Production Setup:**
```bash
OLLAMA_API_URL=http://remote:11434 \
MAX_CONCURRENT_JOBS=10 \
RETRY_MAX_ATTEMPTS=5 \
DEBUG=false \
node build/index.js
```

### Validation with Zod

```
âœ“ URL format validation
âœ“ Model list (at least 1)
âœ“ Bounds checking (concurrency: 1-100)
âœ“ Type checking
âœ— Model availability check (todo)
âœ— Ollama connectivity test (todo)
```

---

## ğŸ” Strengths âœ…

| Feature | Benefit |
|---------|---------|
| **Async Architecture** | Non-blocking, scalable |
| **Circuit Breaker** | Prevents cascading failures |
| **Exponential Backoff** | Intelligent retry strategy |
| **Persistent Storage** | Conversation history recovery |
| **Parallel Queries** | 3Ã— faster than sequential |
| **Progress Tracking** | Real-time feedback |
| **Dynamic Prompts** | Different AI perspectives |
| **Health Checks** | System visibility |

---

## âš ï¸ Weaknesses & TODOs âŒ

| Issue | Severity | Impact | Fix |
|-------|----------|--------|-----|
| Max 2 concurrent jobs | ğŸ”´ HIGH | Bottleneck | Set to 5-10 |
| Job progress not persisted | ğŸ”´ HIGH | Loss on crash | Save to DB |
| Hardcoded 500s timeout | ğŸŸ¡ MEDIUM | Inflexible | Make configurable |
| No auto cleanup | ğŸŸ¡ MEDIUM | DB grows | Implement timer |
| No test coverage | ğŸ”´ HIGH | Risky changes | Add tests |
| No rate limiting | ğŸŸ¡ MEDIUM | Abuse risk | Implement bucket |
| Limited logging | ğŸŸ¢ LOW | Debugging hard | Structured logs |
| No metrics | ğŸŸ¢ LOW | No observability | Prometheus export |

---

## ğŸš€ Quick Start Performance

### Typical Timings

```
Submission:        < 10ms    (returns immediately)
Initial estimate:  30s       (3 models Ã— 10s each)

Model queries:
  - Model 1:       8-12s     (parallel)
  - Model 2:       8-12s     (parallel)
  - Model 3:       8-12s     (parallel)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total execution:   ~12s      (parallel wins!)

User polling: 100ms          (instant feedback)
```

### Resource Usage

```
Memory per session:
  - 40 messages max in memory
  - ~200KB for typical session
  - Total: < 50MB for 100 sessions

Database:
  - ~5KB per 100 messages
  - Grows linearly with usage
  - Needs manual cleanup (24-30 day retention recommended)
```

---

## ğŸ“Š Tools Available

| Tool | Purpose | Blocking | Response Time |
|------|---------|----------|----------------|
| `query-models` | Get multiple perspectives | No | Immediate (returns Job ID) |
| `analyze-with-thinking` | Deep analysis with reasoning | No | Immediate (returns Job ID) |
| `get-job-progress` | Check job status | Yes | Instant |
| `get-job-result` | Retrieve completed results | Yes | Instant (if ready) |
| `list-jobs` | See all jobs | Yes | Instant |
| `cancel-job` | Cancel pending job | Yes | Instant |
| `health-check` | System status | Yes | ~500ms |
| `manage-conversation` | View/clear history | Yes | Instant |

---

## ğŸ”§ Recommended Improvements (Priority Order)

### Week 1 (Quick Wins)
- [ ] Increase `maxConcurrentJobs` from 2 â†’ 5-10
- [ ] Make timeout configurable (not hardcoded 500s)
- [ ] Add auto-cleanup timer for database
- [ ] Persist job progress to database

### Week 2-3 (Stability)
- [ ] Comprehensive test suite (unit + integration)
- [ ] Implement rate limiting
- [ ] Add memory limits for in-memory history
- [ ] Implement proper job cancellation

### Month 2 (Observability)
- [ ] Structured logging (Winston/Pino)
- [ ] Metrics export (Prometheus)
- [ ] Distributed tracing support
- [ ] Better error messages

### Future (Advanced)
- [ ] Result streaming
- [ ] Job dependencies
- [ ] Model fallback chains
- [ ] WebSocket support

---

## ğŸ“š File Reference

```
src/index.ts (500+ lines)
â”œâ”€ MCP server setup
â”œâ”€ Tool definitions (query-models, analyze-thinking, etc)
â”œâ”€ Job execution handlers
â”œâ”€ Conversation history management
â””â”€ Request/response formatting

src/jobqueue.ts (300+ lines)
â”œâ”€ Job class definition
â”œâ”€ Queue management (pending/running/completed)
â”œâ”€ Progress tracking
â”œâ”€ Concurrency control
â””â”€ Job lifecycle callbacks

src/database.ts (350+ lines)
â”œâ”€ SQLite initialization
â”œâ”€ Message persistence
â”œâ”€ Job tracking
â”œâ”€ Cleanup utilities
â””â”€ Statistics reporting

src/config.ts (300+ lines)
â”œâ”€ CLI argument parsing
â”œâ”€ Environment variable loading
â”œâ”€ Zod validation schema
â”œâ”€ Default configuration
â””â”€ Error reporting

src/retry.ts (200+ lines)
â”œâ”€ Circuit breaker class
â”œâ”€ Retry logic with exponential backoff
â”œâ”€ Error classification
â””â”€ Timeout handling
```

---

## ğŸ“ Key Learnings

1. **Non-blocking is Essential** - Async job submission prevents UI freezing
2. **Circuit Breakers Save Cascades** - Prevents system meltdown when Ollama is down
3. **Parallel > Sequential** - 3Ã— speedup from parallel queries
4. **Persistence Matters** - Database recovery on restart builds confidence
5. **Configuration Flexibility** - CLI + env + defaults satisfies power users & ops
6. **Progress Feedback** - Users appreciate knowing how long things take
7. **Conservative is Safer** - But can hurt performance (need testing to scale)
8. **Validation Prevents Errors** - Zod catches issues early with good messages

---

## ğŸ¤” Questions for Stakeholders

1. **Scale:** Are we targeting single-user or multi-user deployments?
2. **SLO:** What are the latency targets (e.g., < 20s for results)?
3. **Retention:** How long should conversation history be kept?
4. **Models:** Will we support > 3 models? Should they be discoverable?
5. **Observability:** Do we need metrics, logs, traces?
6. **Testing:** What's our test coverage goal?
7. **Deployment:** Docker? Kubernetes? Standalone?

---

## ğŸ“– Next Steps

1. **Read Full Analysis:** `PROJECT_ARCHITECTURE_ANALYSIS.md`
2. **Review High-Priority Fixes:** Section 7.1
3. **Run Tests:** `npm test`
4. **Start Development:** Pick first issue to fix
5. **Monitor Performance:** Use health-check tool

---

**Last Updated:** November 13, 2025  
**Status:** Complete Analysis âœ“  
**Ready for:** Development, Optimization, Testing
