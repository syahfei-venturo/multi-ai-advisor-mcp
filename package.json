{
  "name": "multi-model-advisor",
  "version": "1.0.0",
  "description": "MCP server that queries multiple Ollama models",
  "main": "build/index.js",
  "type": "module",
  "scripts": {
    "build": "tsc && chmod 755 build/index.js",
    "start": "node build/index.js",
    "start:debug": "node build/index.js --debug",
    "start:remote": "node build/index.js --ollama-url http://localhost:11434",
    "start:custom": "node build/index.js --models llama3:latest,neural-chat --debug",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "mcp",
    "ollama",
    "ai"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.7.0",
    "dotenv": "^16.4.7",
    "node-fetch": "^3.3.2",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/node": "^22.13.13",
    "@types/node-fetch": "^2.6.12",
    "typescript": "^5.8.2"
  }
}
